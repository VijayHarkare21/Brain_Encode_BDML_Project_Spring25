{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0abeba1-a154-40f2-8f7c-cf5084363f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "983b49ce-3183-4d49-a945-3b15bbce326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "TEXT_PATH = r\"/scratch/vjh9526/bdml_2025/project/code/classifiers/data/combined_data_with_labels.csv\"\n",
    "RESULTS_PATH = r'/scratch/vjh9526/bdml_2025/project/code/classifiers/natural_modes/results_new_text.pkl'\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "876c4862-70c8-45a7-8e4d-95568d0a230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_labels(csv_path: str):\n",
    "    print(f\"[INFO] Loading text labels from {csv_path}\")\n",
    "    df = pd.read_csv(csv_path, delimiter=\";\")\n",
    "    # assume the sentence is in column 2\n",
    "    sentences = df.iloc[:, 2].astype(str).str.strip().str.lower()\n",
    "    categories = df[\"category\"].astype(str).str.strip()\n",
    "    return dict(zip(sentences, categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74afdc9f-433d-45b4-bae7-d935fad7ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT and RoBERTa models and tokenizers\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "roberta_model_name = 'roberta-base'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(roberta_model_name)\n",
    "roberta_model = RobertaModel.from_pretrained(roberta_model_name)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model.to(device)\n",
    "roberta_model.to(device)\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embeddings(sentences):\n",
    "    inputs = bert_tokenizer(sentences, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# Function to get RoBERTa embeddings\n",
    "def get_roberta_embeddings(sentences):\n",
    "    inputs = roberta_tokenizer(sentences, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = roberta_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dd6a69e-2530-446f-93c5-0faa3d96b8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading text labels from /scratch/vjh9526/bdml_2025/project/code/classifiers/data/combined_data_with_labels.csv\n"
     ]
    }
   ],
   "source": [
    "data = load_text_labels(TEXT_PATH)\n",
    "\n",
    "sentences, labels = [],[] \n",
    "for item in data.items():\n",
    "    sentences.append(item[0])\n",
    "    labels.append(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b421be84-cedf-44ec-84e5-f8474aea08ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((365, 768), (365, 768))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get BERT and RoBERTa embeddings for the sentences, that is index 2 of the dataframe\n",
    "bert_embeddings = get_bert_embeddings(sentences)\n",
    "roberta_embeddings = get_roberta_embeddings(sentences)\n",
    "# bert_embeddings.shape, roberta_embeddings.shape\n",
    "\n",
    "# use standard scaler to scale the embeddings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bert_embeddings_scaled = scaler.fit_transform(bert_embeddings)\n",
    "roberta_embeddings_scaled = scaler.fit_transform(roberta_embeddings)\n",
    "bert_embeddings_scaled.shape, roberta_embeddings_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18923827-4dc9-4098-9680-c7a65552b2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((292, 768), (73, 768), (292, 768), (73, 768))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(bert_embeddings, labels, test_size=0.2, random_state=42)\n",
    "X_train_roberta, X_test_roberta, _, _ = train_test_split(roberta_embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "X_train_bert.shape, X_test_bert.shape, X_train_roberta.shape, X_test_roberta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0881aa3f-bf04-489f-af6a-7410863c499c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del bert_embeddings, roberta_embeddings\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57cab7ca-d4e1-43d6-ade4-cba8f69ffdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3ea7097-9607-4243-b5c0-028b42055fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training classifiers on bert features ---\n",
      "\n",
      "--- Using SMOTE on bert features ---\n",
      "Shape of training data is (856, 768)\n",
      "Training dt_SMOTE classifier...\n",
      "[bert-dt_SMOTE] acc=0.3151 precision=0.3714 recall=0.3151 f1=0.3262 time=0.47s\n",
      "Training logistic_SMOTE classifier...\n",
      "[bert-logistic_SMOTE] acc=0.5616 precision=0.6040 recall=0.5616 f1=0.5729 time=0.17s\n",
      "Training nb_SMOTE classifier...\n",
      "[bert-nb_SMOTE] acc=0.5205 precision=0.4908 recall=0.5205 f1=0.4945 time=0.01s\n",
      "Training knn_SMOTE classifier...\n",
      "[bert-knn_SMOTE] acc=0.3014 precision=0.5793 recall=0.3014 f1=0.2727 time=0.01s\n",
      "Training softmax classifier...\n",
      "(856, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/envs/eeg_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.2019, Accuracy: 0.4384\n",
      "Epoch 20, Loss: 0.8077, Accuracy: 0.4932\n",
      "Epoch 30, Loss: 0.6156, Accuracy: 0.5205\n",
      "Epoch 40, Loss: 0.5094, Accuracy: 0.4932\n",
      "Epoch 50, Loss: 0.4529, Accuracy: 0.4932\n",
      "Epoch 60, Loss: 0.3849, Accuracy: 0.5068\n",
      "Epoch 70, Loss: 0.3467, Accuracy: 0.5205\n",
      "Epoch 80, Loss: 0.3152, Accuracy: 0.5205\n",
      "Epoch 90, Loss: 0.2744, Accuracy: 0.5342\n",
      "Epoch 100, Loss: 0.2532, Accuracy: 0.5205\n",
      "[INFO] Best accuracy: 0.5479 at epoch 33\n",
      "[bert-softmax] acc=0.5479 precision=0.5614 recall=0.5205 f1=0.5260\n",
      "Training mlp classifier...\n",
      "(856, 768)\n",
      "Epoch 10, Loss: 0.1981, Accuracy: 0.5890\n",
      "Epoch 20, Loss: 0.0216, Accuracy: 0.5616\n",
      "Epoch 30, Loss: 0.0048, Accuracy: 0.5616\n",
      "Epoch 40, Loss: 0.0028, Accuracy: 0.5479\n",
      "Epoch 50, Loss: 0.0013, Accuracy: 0.5616\n",
      "Epoch 60, Loss: 0.0008, Accuracy: 0.5479\n",
      "Epoch 70, Loss: 0.0008, Accuracy: 0.5479\n",
      "Epoch 80, Loss: 0.0006, Accuracy: 0.5616\n",
      "Epoch 90, Loss: 0.0004, Accuracy: 0.5479\n",
      "Epoch 100, Loss: 0.0004, Accuracy: 0.5479\n",
      "[INFO] Best accuracy: 0.6027 at epoch 7\n",
      "[bert-mlp] acc=0.6027 precision=0.5845 recall=0.5479 f1=0.5581\n",
      "\n",
      "--- Training classifiers on bert features ---\n",
      "Shape of training data is (292, 768)\n",
      "Training dt classifier...\n",
      "[bert-dt] acc=0.4247 precision=0.4201 recall=0.4247 f1=0.4144 time=0.15s\n",
      "Training logistic classifier...\n",
      "[bert-logistic] acc=0.5068 precision=0.5178 recall=0.5068 f1=0.4997 time=0.12s\n",
      "Training nb classifier...\n",
      "[bert-nb] acc=0.5616 precision=0.5982 recall=0.5616 f1=0.5620 time=0.01s\n",
      "Training knn classifier...\n",
      "[bert-knn] acc=0.4932 precision=0.5460 recall=0.4932 f1=0.4865 time=0.01s\n",
      "Training softmax classifier...\n",
      "(292, 768)\n",
      "Epoch 10, Loss: 1.5885, Accuracy: 0.4247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/envs/eeg_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 1.3204, Accuracy: 0.4795\n",
      "Epoch 30, Loss: 1.1237, Accuracy: 0.4932\n",
      "Epoch 40, Loss: 1.0168, Accuracy: 0.5205\n",
      "Epoch 50, Loss: 0.9685, Accuracy: 0.5479\n",
      "Epoch 60, Loss: 0.8738, Accuracy: 0.5616\n",
      "Epoch 70, Loss: 0.7923, Accuracy: 0.5616\n",
      "Epoch 80, Loss: 0.7383, Accuracy: 0.5616\n",
      "Epoch 90, Loss: 0.6791, Accuracy: 0.5753\n",
      "Epoch 100, Loss: 0.6921, Accuracy: 0.5890\n",
      "[INFO] Best accuracy: 0.6027 at epoch 93\n",
      "[bert-softmax] acc=0.6027 precision=0.5807 recall=0.5890 f1=0.5721\n",
      "Training mlp classifier...\n",
      "(292, 768)\n",
      "Epoch 10, Loss: 1.0876, Accuracy: 0.4795\n",
      "Epoch 20, Loss: 0.4190, Accuracy: 0.5890\n",
      "Epoch 30, Loss: 0.1892, Accuracy: 0.5890\n",
      "Epoch 40, Loss: 0.0417, Accuracy: 0.5616\n",
      "Epoch 50, Loss: 0.0206, Accuracy: 0.5342\n",
      "Epoch 60, Loss: 0.0075, Accuracy: 0.5479\n",
      "Epoch 70, Loss: 0.0051, Accuracy: 0.5205\n",
      "Epoch 80, Loss: 0.0037, Accuracy: 0.5479\n",
      "Epoch 90, Loss: 0.0023, Accuracy: 0.5479\n",
      "Epoch 100, Loss: 0.0033, Accuracy: 0.5342\n",
      "[INFO] Best accuracy: 0.6575 at epoch 24\n",
      "[bert-mlp] acc=0.6575 precision=0.5752 recall=0.5342 f1=0.5433\n",
      "\n",
      "--- Training classifiers on roberta features ---\n",
      "\n",
      "--- Using SMOTE on roberta features ---\n",
      "Shape of training data is (856, 768)\n",
      "Training dt_SMOTE classifier...\n",
      "[roberta-dt_SMOTE] acc=0.3425 precision=0.3620 recall=0.3425 f1=0.3411 time=0.49s\n",
      "Training logistic_SMOTE classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/envs/eeg_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[roberta-logistic_SMOTE] acc=0.4932 precision=0.5210 recall=0.4932 f1=0.4839 time=0.49s\n",
      "Training nb_SMOTE classifier...\n",
      "[roberta-nb_SMOTE] acc=0.4247 precision=0.5065 recall=0.4247 f1=0.4379 time=0.01s\n",
      "Training knn_SMOTE classifier...\n",
      "[roberta-knn_SMOTE] acc=0.2055 precision=0.5313 recall=0.2055 f1=0.1861 time=0.01s\n",
      "Training softmax classifier...\n",
      "(856, 768)\n",
      "Epoch 10, Loss: 1.7687, Accuracy: 0.3425\n",
      "Epoch 20, Loss: 1.5194, Accuracy: 0.3288\n",
      "Epoch 30, Loss: 1.3178, Accuracy: 0.3425\n",
      "Epoch 40, Loss: 1.1625, Accuracy: 0.3699\n",
      "Epoch 50, Loss: 1.0377, Accuracy: 0.3973\n",
      "Epoch 60, Loss: 0.9411, Accuracy: 0.4795\n",
      "Epoch 70, Loss: 0.8523, Accuracy: 0.4795\n",
      "Epoch 80, Loss: 0.7956, Accuracy: 0.4932\n",
      "Epoch 90, Loss: 0.7401, Accuracy: 0.4932\n",
      "Epoch 100, Loss: 0.6893, Accuracy: 0.5068\n",
      "[INFO] Best accuracy: 0.5068 at epoch 92\n",
      "[roberta-softmax] acc=0.5068 precision=0.5793 recall=0.5068 f1=0.5043\n",
      "Training mlp classifier...\n",
      "(856, 768)\n",
      "Epoch 10, Loss: 0.5564, Accuracy: 0.4795\n",
      "Epoch 20, Loss: 0.2051, Accuracy: 0.4932\n",
      "Epoch 30, Loss: 0.0688, Accuracy: 0.5342\n",
      "Epoch 40, Loss: 0.0238, Accuracy: 0.5479\n",
      "Epoch 50, Loss: 0.0103, Accuracy: 0.5616\n",
      "Epoch 60, Loss: 0.0073, Accuracy: 0.5479\n",
      "Epoch 70, Loss: 0.0037, Accuracy: 0.5342\n",
      "Epoch 80, Loss: 0.0029, Accuracy: 0.5753\n",
      "Epoch 90, Loss: 0.0026, Accuracy: 0.5068\n",
      "Epoch 100, Loss: 0.0028, Accuracy: 0.5342\n",
      "[INFO] Best accuracy: 0.5890 at epoch 37\n",
      "[roberta-mlp] acc=0.5890 precision=0.5656 recall=0.5342 f1=0.5115\n",
      "\n",
      "--- Training classifiers on roberta features ---\n",
      "Shape of training data is (292, 768)\n",
      "Training dt classifier...\n",
      "[roberta-dt] acc=0.2740 precision=0.2736 recall=0.2740 f1=0.2693 time=0.15s\n",
      "Training logistic classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/envs/eeg_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[roberta-logistic] acc=0.4384 precision=0.3880 recall=0.4384 f1=0.3854 time=0.34s\n",
      "Training nb classifier...\n",
      "[roberta-nb] acc=0.3151 precision=0.3717 recall=0.3151 f1=0.3134 time=0.01s\n",
      "Training knn classifier...\n",
      "[roberta-knn] acc=0.3425 precision=0.3583 recall=0.3425 f1=0.3433 time=0.01s\n",
      "Training softmax classifier...\n",
      "(292, 768)\n",
      "Epoch 10, Loss: 1.8034, Accuracy: 0.4110\n",
      "Epoch 20, Loss: 1.6452, Accuracy: 0.4110\n",
      "Epoch 30, Loss: 1.6334, Accuracy: 0.4110\n",
      "Epoch 40, Loss: 1.5434, Accuracy: 0.4110\n",
      "Epoch 50, Loss: 1.4357, Accuracy: 0.4247\n",
      "Epoch 60, Loss: 1.4267, Accuracy: 0.4247\n",
      "Epoch 70, Loss: 1.4070, Accuracy: 0.4110\n",
      "Epoch 80, Loss: 1.3704, Accuracy: 0.4247\n",
      "Epoch 90, Loss: 1.3301, Accuracy: 0.4110\n",
      "Epoch 100, Loss: 1.3032, Accuracy: 0.4247\n",
      "[INFO] Best accuracy: 0.4384 at epoch 42\n",
      "[roberta-softmax] acc=0.4384 precision=0.2783 recall=0.4247 f1=0.3118\n",
      "Training mlp classifier...\n",
      "(292, 768)\n",
      "Epoch 10, Loss: 1.6549, Accuracy: 0.4384\n",
      "Epoch 20, Loss: 1.3036, Accuracy: 0.4932\n",
      "Epoch 30, Loss: 0.8632, Accuracy: 0.5479\n",
      "Epoch 40, Loss: 0.5823, Accuracy: 0.5205\n",
      "Epoch 50, Loss: 0.3440, Accuracy: 0.5205\n",
      "Epoch 60, Loss: 0.1900, Accuracy: 0.5616\n",
      "Epoch 70, Loss: 0.0892, Accuracy: 0.5479\n",
      "Epoch 80, Loss: 0.0588, Accuracy: 0.5753\n",
      "Epoch 90, Loss: 0.0422, Accuracy: 0.5753\n",
      "Epoch 100, Loss: 0.0215, Accuracy: 0.5753\n",
      "[INFO] Best accuracy: 0.6301 at epoch 65\n",
      "[roberta-mlp] acc=0.6301 precision=0.5455 recall=0.5753 f1=0.5477\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Classifier Training -------------------\n",
    "from classifiers_eeg_embeds import SoftmaxClassifier, MLPClassifier, train_pytorch_model\n",
    "from sklearn.tree           import DecisionTreeClassifier\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.naive_bayes   import GaussianNB\n",
    "from sklearn.neighbors     import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics       import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import time\n",
    "\n",
    "embed_models = [\"bert\", \"roberta\"]\n",
    "oversample = [\"yes\", \"no\"]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name in embed_models:\n",
    "    for over in oversample:\n",
    "        print(f\"\\n--- Training classifiers on {name} features ---\")\n",
    "        if name == \"bert\":\n",
    "            X_tr = X_train_bert\n",
    "            y_tr = y_train\n",
    "            X_val = X_test_bert\n",
    "            y_val = y_test\n",
    "        else:\n",
    "            X_tr = X_train_roberta\n",
    "            y_tr = y_train\n",
    "            X_val = X_test_roberta\n",
    "            y_val = y_test\n",
    "\n",
    "        if over == \"yes\":\n",
    "            print(f\"\\n--- Using SMOTE on {name} features ---\")\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_tr, y_tr = smote.fit_resample(X_tr, y_tr)\n",
    "        \n",
    "        num_classes = len(np.unique(y_tr))\n",
    "        input_dim   = X_tr.shape[1]\n",
    "        results[name] = {}\n",
    "    \n",
    "        print(f\"Shape of training data is {X_tr.shape}\")\n",
    "        # --- scikitâ€‘learn classifiers ---\n",
    "        for clf_name_org, clf in {\n",
    "            'dt'      : DecisionTreeClassifier(random_state=42),\n",
    "            'logistic': LogisticRegression(\n",
    "                             multi_class='multinomial',\n",
    "                             max_iter=1000,\n",
    "                             random_state=42\n",
    "                         ),\n",
    "            'nb'      : GaussianNB(),\n",
    "            'knn'     : KNeighborsClassifier(n_neighbors=5)\n",
    "        }.items():\n",
    "            if over == \"yes\":\n",
    "                clf_name = f\"{clf_name_org}_SMOTE\"\n",
    "            else:\n",
    "                clf_name = clf_name_org\n",
    "            print(f\"Training {clf_name} classifier...\")\n",
    "            t0 = time.time()\n",
    "            clf.fit(X_tr, y_tr)\n",
    "            preds = clf.predict(X_val)\n",
    "            acc       = accuracy_score(y_val, preds)\n",
    "            prec      = precision_score(y_val, preds, average='weighted', zero_division=0)\n",
    "            rec       = recall_score(y_val, preds, average='weighted', zero_division=0)\n",
    "            f1        = f1_score(y_val, preds, average='weighted', zero_division=0)\n",
    "            print(f\"[{name}-{clf_name}] acc={acc:.4f} precision={prec:.4f} \"\n",
    "                  f\"recall={rec:.4f} f1={f1:.4f} time={time.time()-t0:.2f}s\")\n",
    "    \n",
    "            results[name][clf_name] = {\n",
    "                'accuracy' : acc,\n",
    "                'precision': prec,\n",
    "                'recall'   : rec,\n",
    "                'f1'       : f1,\n",
    "                # 'report'   : classification_report(\n",
    "                #                  y_val, preds,\n",
    "                #                  target_names=unique_labels,\n",
    "                #                  zero_division=0\n",
    "                #              ),\n",
    "                'cm'       : confusion_matrix(y_val, preds)\n",
    "            }\n",
    "            del clf\n",
    "    \n",
    "        # --- PyTorch classifiers ---\n",
    "        for clf_name, Model in {\n",
    "            'softmax': SoftmaxClassifier,\n",
    "            'mlp'    : lambda in_dim, n_cls: MLPClassifier(in_dim, [1024, 512], n_cls)\n",
    "        }.items():\n",
    "            print(f\"Training {clf_name} classifier...\")\n",
    "            # instantiate\n",
    "            if clf_name == 'softmax':\n",
    "                model = Model(input_dim, num_classes)\n",
    "            else:\n",
    "                model = Model(input_dim, num_classes)\n",
    "            pt = train_pytorch_model(\n",
    "                model, X_tr, X_val, y_tr, y_val,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                device=device,\n",
    "                early_stopping=100\n",
    "            )\n",
    "            preds = pt['y_pred']\n",
    "            acc   = pt['accuracy']\n",
    "            prec  = precision_score(y_val, preds, average='weighted', zero_division=0)\n",
    "            rec   = recall_score(y_val, preds, average='weighted', zero_division=0)\n",
    "            f1_   = f1_score(y_val, preds, average='weighted', zero_division=0)\n",
    "            print(f\"[{name}-{clf_name}] acc={acc:.4f} precision={prec:.4f} \"\n",
    "                  f\"recall={rec:.4f} f1={f1_:.4f}\")\n",
    "    \n",
    "            results[name][clf_name] = {\n",
    "                'accuracy'      : acc,\n",
    "                'precision'     : prec,\n",
    "                'recall'        : rec,\n",
    "                'f1'            : f1_,\n",
    "                'train_losses'  : pt['train_losses'],\n",
    "                'val_accuracies': pt['val_accuracies'],\n",
    "                # 'report'        : classification_report(\n",
    "                #                       y_val, preds,\n",
    "                #                       target_names=unique_labels,\n",
    "                #                       zero_division=0\n",
    "                #                   ),\n",
    "                'cm'            : confusion_matrix(y_val, preds)\n",
    "            }\n",
    "            del model, pt\n",
    "    \n",
    "        # free memory before next extractor\n",
    "        del X_tr, y_tr, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaa81625-5df2-435e-b798-a7e9f75e440f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert': {'dt': {'accuracy': 0.4246575342465753,\n",
       "   'precision': 0.4200913242009132,\n",
       "   'recall': 0.4246575342465753,\n",
       "   'f1': 0.4143746664294609,\n",
       "   'cm': array([[ 2,  0,  0,  0,  0,  2,  2,  0],\n",
       "          [ 0,  2,  0,  1,  1,  2,  1,  1],\n",
       "          [ 0,  0,  0,  0,  2,  2,  0,  0],\n",
       "          [ 1,  0,  0,  0,  0,  2,  0,  0],\n",
       "          [ 0,  1,  0,  0,  0,  1,  0,  2],\n",
       "          [ 2,  1,  0,  2,  1, 15,  5,  4],\n",
       "          [ 0,  0,  0,  0,  0,  1, 12,  1],\n",
       "          [ 1,  2,  0,  0,  0,  0,  1,  0]])},\n",
       "  'logistic': {'accuracy': 0.5068493150684932,\n",
       "   'precision': 0.5177978414279784,\n",
       "   'recall': 0.5068493150684932,\n",
       "   'f1': 0.4997215383428375,\n",
       "   'cm': array([[ 3,  0,  0,  0,  0,  0,  2,  1],\n",
       "          [ 0,  3,  0,  0,  0,  3,  2,  0],\n",
       "          [ 0,  0,  2,  0,  0,  2,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0,  3,  0,  0],\n",
       "          [ 0,  0,  0,  0,  1,  1,  1,  1],\n",
       "          [ 0,  2,  0,  0,  1, 18,  9,  0],\n",
       "          [ 1,  1,  0,  0,  0,  4,  8,  0],\n",
       "          [ 0,  0,  0,  0,  1,  1,  0,  2]])},\n",
       "  'nb': {'accuracy': 0.5616438356164384,\n",
       "   'precision': 0.5981607254774056,\n",
       "   'recall': 0.5616438356164384,\n",
       "   'f1': 0.5620277007815674,\n",
       "   'cm': array([[ 2,  0,  0,  0,  0,  1,  1,  2],\n",
       "          [ 0,  5,  0,  1,  0,  1,  1,  0],\n",
       "          [ 0,  0,  1,  0,  1,  1,  1,  0],\n",
       "          [ 0,  0,  0,  2,  0,  1,  0,  0],\n",
       "          [ 0,  0,  0,  0,  1,  0,  1,  2],\n",
       "          [ 2,  3,  0,  0,  2, 19,  3,  1],\n",
       "          [ 0,  2,  0,  0,  0,  3,  9,  0],\n",
       "          [ 0,  0,  0,  0,  0,  1,  1,  2]])},\n",
       "  'knn': {'accuracy': 0.4931506849315068,\n",
       "   'precision': 0.5459730326411623,\n",
       "   'recall': 0.4931506849315068,\n",
       "   'f1': 0.4865238061671248,\n",
       "   'cm': array([[ 4,  0,  0,  0,  0,  1,  1,  0],\n",
       "          [ 0,  6,  0,  0,  0,  1,  1,  0],\n",
       "          [ 1,  0,  1,  0,  1,  0,  1,  0],\n",
       "          [ 1,  0,  0,  1,  0,  0,  1,  0],\n",
       "          [ 0,  0,  0,  0,  1,  1,  2,  0],\n",
       "          [ 2,  5,  0,  0,  2, 16,  4,  1],\n",
       "          [ 1,  3,  0,  0,  0,  3,  7,  0],\n",
       "          [ 1,  0,  0,  0,  0,  1,  2,  0]])},\n",
       "  'softmax': {'accuracy': 0.589041095890411,\n",
       "   'precision': 0.589456205894562,\n",
       "   'recall': 0.5616438356164384,\n",
       "   'f1': 0.5316690467375399,\n",
       "   'train_losses': [2.0930944681167603,\n",
       "    1.9622952342033386,\n",
       "    1.8488088250160217,\n",
       "    1.7787813544273376,\n",
       "    1.802992343902588,\n",
       "    1.669167160987854,\n",
       "    1.624158799648285,\n",
       "    1.7277785539627075,\n",
       "    1.5817159414291382,\n",
       "    1.6010708808898926,\n",
       "    1.5705657601356506,\n",
       "    1.4788355827331543,\n",
       "    1.5263531804084778,\n",
       "    1.5157646536827087,\n",
       "    1.4521609544754028,\n",
       "    1.4259969592094421,\n",
       "    1.4241074323654175,\n",
       "    1.3657758235931396,\n",
       "    1.4009391069412231,\n",
       "    1.3184195756912231,\n",
       "    1.3087033033370972,\n",
       "    1.3064422607421875,\n",
       "    1.2691493034362793,\n",
       "    1.2564406991004944,\n",
       "    1.3389798998832703,\n",
       "    1.261959731578827,\n",
       "    1.218607783317566,\n",
       "    1.1423890590667725,\n",
       "    1.2056923508644104,\n",
       "    1.2344805598258972,\n",
       "    1.173018455505371,\n",
       "    1.0990858674049377,\n",
       "    1.1472870707511902,\n",
       "    1.1139153242111206,\n",
       "    1.1954959034919739,\n",
       "    1.1109638214111328,\n",
       "    1.1285618543624878,\n",
       "    1.1275729537010193,\n",
       "    1.0898690819740295,\n",
       "    1.096522569656372,\n",
       "    1.0486887693405151,\n",
       "    1.0349102020263672,\n",
       "    1.0377212166786194,\n",
       "    0.9331177473068237,\n",
       "    1.0002540349960327,\n",
       "    0.9417259693145752,\n",
       "    1.0617932677268982,\n",
       "    1.0367827415466309,\n",
       "    0.9353901147842407,\n",
       "    0.9676612317562103,\n",
       "    1.000213772058487,\n",
       "    1.002296507358551,\n",
       "    0.945923924446106,\n",
       "    0.9907335638999939,\n",
       "    0.9514132738113403,\n",
       "    0.9227627515792847,\n",
       "    0.8886973261833191,\n",
       "    0.8864264488220215,\n",
       "    0.874154269695282,\n",
       "    0.9556019902229309,\n",
       "    0.9054962694644928,\n",
       "    0.8573078215122223,\n",
       "    0.8783029019832611,\n",
       "    0.8476516008377075,\n",
       "    0.8423779308795929,\n",
       "    0.8992263376712799,\n",
       "    0.7813578248023987,\n",
       "    0.8565717339515686,\n",
       "    0.7571310997009277,\n",
       "    0.7878937721252441,\n",
       "    0.8952520489692688,\n",
       "    0.8564208745956421,\n",
       "    0.8963389098644257,\n",
       "    0.8085159957408905,\n",
       "    0.7479261755943298,\n",
       "    0.8165488243103027,\n",
       "    0.7957906126976013,\n",
       "    0.7217375338077545,\n",
       "    0.8017177581787109,\n",
       "    0.733435332775116,\n",
       "    0.741906613111496,\n",
       "    0.8262029588222504,\n",
       "    0.7506392896175385,\n",
       "    0.7540927231311798,\n",
       "    0.7378406226634979,\n",
       "    0.7179030478000641,\n",
       "    0.7073556482791901,\n",
       "    0.7097091972827911,\n",
       "    0.7573697865009308,\n",
       "    0.6845227181911469,\n",
       "    0.7527768611907959,\n",
       "    0.7547803223133087,\n",
       "    0.7248034477233887,\n",
       "    0.6981936693191528,\n",
       "    0.7015913426876068,\n",
       "    0.676268607378006,\n",
       "    0.7415775060653687,\n",
       "    0.6856071650981903,\n",
       "    0.6760877668857574,\n",
       "    0.7314577996730804],\n",
       "   'val_accuracies': [0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.4383561643835616,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4520547945205479,\n",
       "    0.4520547945205479,\n",
       "    0.4657534246575342,\n",
       "    0.4520547945205479,\n",
       "    0.4794520547945205,\n",
       "    0.4794520547945205,\n",
       "    0.4657534246575342,\n",
       "    0.4657534246575342,\n",
       "    0.4931506849315068,\n",
       "    0.4794520547945205,\n",
       "    0.4794520547945205,\n",
       "    0.4794520547945205,\n",
       "    0.4794520547945205,\n",
       "    0.4657534246575342,\n",
       "    0.4794520547945205,\n",
       "    0.4794520547945205,\n",
       "    0.4931506849315068,\n",
       "    0.4794520547945205,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.4931506849315068,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5205479452054794,\n",
       "    0.5205479452054794,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5205479452054794,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.547945205479452,\n",
       "    0.547945205479452,\n",
       "    0.547945205479452,\n",
       "    0.547945205479452,\n",
       "    0.547945205479452,\n",
       "    0.547945205479452,\n",
       "    0.547945205479452,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.547945205479452,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.589041095890411,\n",
       "    0.589041095890411,\n",
       "    0.589041095890411,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5753424657534246,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384],\n",
       "   'cm': array([[ 2,  0,  0,  0,  0,  2,  2,  0],\n",
       "          [ 0,  2,  0,  0,  0,  5,  1,  0],\n",
       "          [ 0,  0,  2,  0,  0,  2,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0,  3,  0,  0],\n",
       "          [ 0,  0,  0,  0,  1,  1,  1,  1],\n",
       "          [ 2,  0,  0,  0,  1, 24,  3,  0],\n",
       "          [ 0,  0,  0,  0,  0,  6,  8,  0],\n",
       "          [ 0,  0,  0,  0,  0,  1,  1,  2]])},\n",
       "  'mlp': {'accuracy': 0.6027397260273972,\n",
       "   'precision': 0.5789124117891241,\n",
       "   'recall': 0.5342465753424658,\n",
       "   'f1': 0.5384574970011163,\n",
       "   'train_losses': [2.062758684158325,\n",
       "    2.03141987323761,\n",
       "    1.935539960861206,\n",
       "    1.8746672868728638,\n",
       "    1.8859783411026,\n",
       "    1.8558156490325928,\n",
       "    1.7865394353866577,\n",
       "    1.7644073367118835,\n",
       "    1.7802388668060303,\n",
       "    1.708615005016327,\n",
       "    1.661109983921051,\n",
       "    1.6534665822982788,\n",
       "    1.5943829417228699,\n",
       "    1.5869134068489075,\n",
       "    1.53502357006073,\n",
       "    1.599054753780365,\n",
       "    1.4684670567512512,\n",
       "    1.6084893345832825,\n",
       "    1.4599292278289795,\n",
       "    1.3860661387443542,\n",
       "    1.408534824848175,\n",
       "    1.4143866896629333,\n",
       "    1.3677396178245544,\n",
       "    1.1768223643302917,\n",
       "    1.2821633219718933,\n",
       "    1.2065627574920654,\n",
       "    1.2213170528411865,\n",
       "    1.119273602962494,\n",
       "    1.1345071196556091,\n",
       "    1.0960350036621094,\n",
       "    1.184699296951294,\n",
       "    0.949444979429245,\n",
       "    1.0409479439258575,\n",
       "    0.8797829747200012,\n",
       "    0.8979610800743103,\n",
       "    0.9110636711120605,\n",
       "    0.7947328090667725,\n",
       "    0.8562360405921936,\n",
       "    0.6836809813976288,\n",
       "    0.774446576833725,\n",
       "    0.6717929542064667,\n",
       "    0.6529162526130676,\n",
       "    0.5351608842611313,\n",
       "    0.6220559477806091,\n",
       "    0.646205484867096,\n",
       "    0.5445022583007812,\n",
       "    0.5549031496047974,\n",
       "    0.6123761683702469,\n",
       "    0.560866042971611,\n",
       "    0.4785067290067673,\n",
       "    0.4858284592628479,\n",
       "    0.383747935295105,\n",
       "    0.47637805342674255,\n",
       "    0.3480294495820999,\n",
       "    0.34079310297966003,\n",
       "    0.3513612300157547,\n",
       "    0.31089724600315094,\n",
       "    0.3120170086622238,\n",
       "    0.28597158938646317,\n",
       "    0.23439985513687134,\n",
       "    0.24979373067617416,\n",
       "    0.29232990741729736,\n",
       "    0.24674154818058014,\n",
       "    0.20381785184144974,\n",
       "    0.22831270843744278,\n",
       "    0.16354494914412498,\n",
       "    0.20784207433462143,\n",
       "    0.1490681916475296,\n",
       "    0.147108294069767,\n",
       "    0.13193891569972038,\n",
       "    0.1581648513674736,\n",
       "    0.14686422795057297,\n",
       "    0.11812495440244675,\n",
       "    0.12062625586986542,\n",
       "    0.11902277916669846,\n",
       "    0.08392280340194702,\n",
       "    0.04775263927876949,\n",
       "    0.06810681335628033,\n",
       "    0.0683539304882288,\n",
       "    0.10715097561478615,\n",
       "    0.08026235923171043,\n",
       "    0.06606421992182732,\n",
       "    0.0718863196671009,\n",
       "    0.04974590428173542,\n",
       "    0.06288358941674232,\n",
       "    0.08351239189505577,\n",
       "    0.05921238102018833,\n",
       "    0.04863823018968105,\n",
       "    0.08416780456900597,\n",
       "    0.0373751986771822,\n",
       "    0.04257708415389061,\n",
       "    0.04493115749210119,\n",
       "    0.02006770297884941,\n",
       "    0.030010389164090157,\n",
       "    0.02227591397240758,\n",
       "    0.02290960308164358,\n",
       "    0.03346886485815048,\n",
       "    0.018114592880010605,\n",
       "    0.02526841964572668,\n",
       "    0.03453186899423599],\n",
       "   'val_accuracies': [0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.4520547945205479,\n",
       "    0.4657534246575342,\n",
       "    0.4657534246575342,\n",
       "    0.5068493150684932,\n",
       "    0.4794520547945205,\n",
       "    0.4931506849315068,\n",
       "    0.4383561643835616,\n",
       "    0.5068493150684932,\n",
       "    0.4794520547945205,\n",
       "    0.5205479452054794,\n",
       "    0.5068493150684932,\n",
       "    0.547945205479452,\n",
       "    0.5342465753424658,\n",
       "    0.4383561643835616,\n",
       "    0.4657534246575342,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5616438356164384,\n",
       "    0.5753424657534246,\n",
       "    0.547945205479452,\n",
       "    0.4931506849315068,\n",
       "    0.4794520547945205,\n",
       "    0.589041095890411,\n",
       "    0.6027397260273972,\n",
       "    0.589041095890411,\n",
       "    0.547945205479452,\n",
       "    0.547945205479452,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.547945205479452,\n",
       "    0.589041095890411,\n",
       "    0.5068493150684932,\n",
       "    0.4794520547945205,\n",
       "    0.5205479452054794,\n",
       "    0.547945205479452,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.4794520547945205,\n",
       "    0.5205479452054794,\n",
       "    0.6027397260273972,\n",
       "    0.589041095890411,\n",
       "    0.4794520547945205,\n",
       "    0.4931506849315068,\n",
       "    0.5753424657534246,\n",
       "    0.547945205479452,\n",
       "    0.4657534246575342,\n",
       "    0.4794520547945205,\n",
       "    0.4794520547945205,\n",
       "    0.5616438356164384,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5205479452054794,\n",
       "    0.5205479452054794,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.5068493150684932,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.5205479452054794,\n",
       "    0.5342465753424658,\n",
       "    0.547945205479452,\n",
       "    0.547945205479452,\n",
       "    0.4931506849315068,\n",
       "    0.5068493150684932,\n",
       "    0.4657534246575342,\n",
       "    0.5068493150684932,\n",
       "    0.5205479452054794,\n",
       "    0.5068493150684932,\n",
       "    0.4657534246575342,\n",
       "    0.4931506849315068,\n",
       "    0.5068493150684932,\n",
       "    0.5068493150684932,\n",
       "    0.5342465753424658,\n",
       "    0.5342465753424658,\n",
       "    0.5205479452054794,\n",
       "    0.5205479452054794,\n",
       "    0.5205479452054794,\n",
       "    0.5068493150684932,\n",
       "    0.5205479452054794,\n",
       "    0.5068493150684932,\n",
       "    0.5205479452054794,\n",
       "    0.5616438356164384,\n",
       "    0.547945205479452,\n",
       "    0.5342465753424658],\n",
       "   'cm': array([[ 3,  0,  0,  0,  0,  0,  2,  1],\n",
       "          [ 0,  3,  0,  0,  0,  3,  2,  0],\n",
       "          [ 0,  1,  2,  0,  1,  0,  0,  0],\n",
       "          [ 0,  0,  0,  1,  1,  1,  0,  0],\n",
       "          [ 0,  0,  0,  0,  1,  1,  1,  1],\n",
       "          [ 1,  2,  0,  0,  0, 18,  8,  1],\n",
       "          [ 1,  2,  0,  0,  0,  2,  9,  0],\n",
       "          [ 0,  0,  0,  0,  0,  2,  0,  2]])}},\n",
       " 'roberta': {'dt': {'accuracy': 0.273972602739726,\n",
       "   'precision': 0.2736213558131367,\n",
       "   'recall': 0.273972602739726,\n",
       "   'f1': 0.2692960008028501,\n",
       "   'cm': array([[ 0,  1,  0,  0,  0,  3,  2,  0],\n",
       "          [ 0,  4,  0,  0,  0,  1,  3,  0],\n",
       "          [ 0,  1,  0,  0,  0,  3,  0,  0],\n",
       "          [ 1,  0,  0,  0,  0,  0,  2,  0],\n",
       "          [ 0,  0,  0,  0,  2,  0,  0,  2],\n",
       "          [ 3,  4,  1,  3,  2, 12,  3,  2],\n",
       "          [ 1,  1,  1,  0,  2,  6,  2,  1],\n",
       "          [ 0,  2,  0,  1,  0,  1,  0,  0]])},\n",
       "  'logistic': {'accuracy': 0.4383561643835616,\n",
       "   'precision': 0.38801369863013696,\n",
       "   'recall': 0.4383561643835616,\n",
       "   'f1': 0.38536321181573896,\n",
       "   'cm': array([[ 0,  0,  0,  0,  0,  4,  2,  0],\n",
       "          [ 0,  1,  0,  0,  0,  5,  2,  0],\n",
       "          [ 0,  0,  0,  0,  0,  4,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0,  3,  0,  0],\n",
       "          [ 0,  0,  0,  0,  1,  2,  0,  1],\n",
       "          [ 3,  1,  0,  0,  1, 21,  4,  0],\n",
       "          [ 0,  0,  0,  0,  0,  7,  7,  0],\n",
       "          [ 0,  0,  0,  0,  0,  2,  0,  2]])},\n",
       "  'nb': {'accuracy': 0.3150684931506849,\n",
       "   'precision': 0.37169319505296433,\n",
       "   'recall': 0.3150684931506849,\n",
       "   'f1': 0.3134161347683802,\n",
       "   'cm': array([[ 0,  2,  0,  0,  0,  3,  0,  1],\n",
       "          [ 0,  4,  0,  0,  0,  3,  1,  0],\n",
       "          [ 0,  1,  0,  0,  1,  1,  0,  1],\n",
       "          [ 0,  0,  0,  0,  0,  2,  0,  1],\n",
       "          [ 0,  0,  0,  0,  1,  1,  0,  2],\n",
       "          [ 2, 11,  0,  2,  1,  9,  2,  3],\n",
       "          [ 1,  5,  0,  0,  0,  0,  6,  2],\n",
       "          [ 0,  1,  0,  0,  0,  0,  0,  3]])},\n",
       "  'knn': {'accuracy': 0.3424657534246575,\n",
       "   'precision': 0.35831497269853435,\n",
       "   'recall': 0.3424657534246575,\n",
       "   'f1': 0.34327475282350384,\n",
       "   'cm': array([[ 1,  0,  0,  0,  1,  3,  1,  0],\n",
       "          [ 0,  4,  0,  2,  1,  0,  1,  0],\n",
       "          [ 0,  2,  0,  1,  0,  1,  0,  0],\n",
       "          [ 0,  0,  0,  1,  1,  0,  1,  0],\n",
       "          [ 2,  0,  0,  0,  1,  1,  0,  0],\n",
       "          [ 3,  4,  0,  1,  0, 15,  7,  0],\n",
       "          [ 3,  2,  0,  0,  1,  4,  3,  1],\n",
       "          [ 2,  1,  0,  0,  0,  0,  1,  0]])},\n",
       "  'softmax': {'accuracy': 0.4383561643835616,\n",
       "   'precision': 0.25861217156972827,\n",
       "   'recall': 0.4246575342465753,\n",
       "   'f1': 0.3077926639570475,\n",
       "   'train_losses': [2.0506656169891357,\n",
       "    1.996322512626648,\n",
       "    1.879574179649353,\n",
       "    1.8208569288253784,\n",
       "    1.8479799032211304,\n",
       "    1.7841851711273193,\n",
       "    1.7730017304420471,\n",
       "    1.767751693725586,\n",
       "    1.7607936263084412,\n",
       "    1.7398968935012817,\n",
       "    1.7119921445846558,\n",
       "    1.7669273614883423,\n",
       "    1.6485234498977661,\n",
       "    1.7807817459106445,\n",
       "    1.7740594744682312,\n",
       "    1.7244269847869873,\n",
       "    1.6732995510101318,\n",
       "    1.6387458443641663,\n",
       "    1.6520794034004211,\n",
       "    1.6066367626190186,\n",
       "    1.6561073064804077,\n",
       "    1.591046392917633,\n",
       "    1.679875373840332,\n",
       "    1.6711504459381104,\n",
       "    1.5831442475318909,\n",
       "    1.6124672889709473,\n",
       "    1.6259719133377075,\n",
       "    1.635891079902649,\n",
       "    1.6277005672454834,\n",
       "    1.6223565936088562,\n",
       "    1.5478337407112122,\n",
       "    1.5566771626472473,\n",
       "    1.5884920358657837,\n",
       "    1.5497374534606934,\n",
       "    1.563230574131012,\n",
       "    1.5537035465240479,\n",
       "    1.4921079874038696,\n",
       "    1.5181289315223694,\n",
       "    1.5378352999687195,\n",
       "    1.4955907464027405,\n",
       "    1.5478511452674866,\n",
       "    1.4722673296928406,\n",
       "    1.5225255489349365,\n",
       "    1.5711385607719421,\n",
       "    1.4365506768226624,\n",
       "    1.4945682883262634,\n",
       "    1.4285821318626404,\n",
       "    1.5261387825012207,\n",
       "    1.493500292301178,\n",
       "    1.4233339428901672,\n",
       "    1.4181795716285706,\n",
       "    1.4450010061264038,\n",
       "    1.3713757991790771,\n",
       "    1.3912070989608765,\n",
       "    1.4089264273643494,\n",
       "    1.4718474745750427,\n",
       "    1.3296420574188232,\n",
       "    1.4603005051612854,\n",
       "    1.4733558297157288,\n",
       "    1.3546499013900757,\n",
       "    1.4281761050224304,\n",
       "    1.4858446717262268,\n",
       "    1.3520963191986084,\n",
       "    1.3535946011543274,\n",
       "    1.359454333782196,\n",
       "    1.4377767443656921,\n",
       "    1.3780774474143982,\n",
       "    1.40544855594635,\n",
       "    1.400296688079834,\n",
       "    1.2744913697242737,\n",
       "    1.372698426246643,\n",
       "    1.3231045603752136,\n",
       "    1.3666547536849976,\n",
       "    1.3046194911003113,\n",
       "    1.3731489777565002,\n",
       "    1.2927614450454712,\n",
       "    1.3769062757492065,\n",
       "    1.2567030191421509,\n",
       "    1.253611981868744,\n",
       "    1.3351652026176453,\n",
       "    1.279824137687683,\n",
       "    1.2731978297233582,\n",
       "    1.2691328525543213,\n",
       "    1.349259853363037,\n",
       "    1.270546793937683,\n",
       "    1.3764927387237549,\n",
       "    1.2335167527198792,\n",
       "    1.2435537576675415,\n",
       "    1.3477727174758911,\n",
       "    1.3131345510482788,\n",
       "    1.217059075832367,\n",
       "    1.2170629501342773,\n",
       "    1.2735350131988525,\n",
       "    1.2489964365959167,\n",
       "    1.2607282996177673,\n",
       "    1.23693186044693,\n",
       "    1.182930827140808,\n",
       "    1.2011286616325378,\n",
       "    1.2448696494102478,\n",
       "    1.2804298400878906],\n",
       "   'val_accuracies': [0.3972602739726027,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3835616438356164,\n",
       "    0.3835616438356164,\n",
       "    0.3835616438356164,\n",
       "    0.3835616438356164,\n",
       "    0.3835616438356164,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.4383561643835616,\n",
       "    0.410958904109589,\n",
       "    0.4246575342465753],\n",
       "   'cm': array([[ 0,  0,  0,  0,  0,  4,  2,  0],\n",
       "          [ 0,  0,  0,  0,  0,  7,  1,  0],\n",
       "          [ 0,  0,  0,  0,  0,  4,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0,  3,  0,  0],\n",
       "          [ 0,  0,  0,  0,  0,  3,  1,  0],\n",
       "          [ 2,  0,  0,  0,  0, 27,  1,  0],\n",
       "          [ 0,  0,  0,  0,  0, 10,  4,  0],\n",
       "          [ 0,  0,  0,  0,  0,  3,  1,  0]])},\n",
       "  'mlp': {'accuracy': 0.5068493150684932,\n",
       "   'precision': 0.3835616438356164,\n",
       "   'recall': 0.4520547945205479,\n",
       "   'f1': 0.41046866107301233,\n",
       "   'train_losses': [2.0803781747817993,\n",
       "    2.0334426164627075,\n",
       "    1.9788553714752197,\n",
       "    1.867776870727539,\n",
       "    1.8127350211143494,\n",
       "    1.7947190403938293,\n",
       "    1.7263789176940918,\n",
       "    1.7680594325065613,\n",
       "    1.785713791847229,\n",
       "    1.693031370639801,\n",
       "    1.726998507976532,\n",
       "    1.7247905731201172,\n",
       "    1.6774526834487915,\n",
       "    1.6765334606170654,\n",
       "    1.6159858107566833,\n",
       "    1.713182508945465,\n",
       "    1.7069581747055054,\n",
       "    1.633199393749237,\n",
       "    1.6747211813926697,\n",
       "    1.726004421710968,\n",
       "    1.6779029965400696,\n",
       "    1.7276981472969055,\n",
       "    1.6078491806983948,\n",
       "    1.6552513241767883,\n",
       "    1.5989332795143127,\n",
       "    1.609203279018402,\n",
       "    1.4131425619125366,\n",
       "    1.5284684896469116,\n",
       "    1.415743112564087,\n",
       "    1.4956355094909668,\n",
       "    1.4947548508644104,\n",
       "    1.5183080434799194,\n",
       "    1.4842416048049927,\n",
       "    1.4508920907974243,\n",
       "    1.5215206742286682,\n",
       "    1.5019401907920837,\n",
       "    1.420574426651001,\n",
       "    1.3579115271568298,\n",
       "    1.447371244430542,\n",
       "    1.3725138902664185,\n",
       "    1.3373685479164124,\n",
       "    1.4328750967979431,\n",
       "    1.2715756297111511,\n",
       "    1.208813190460205,\n",
       "    1.1992241740226746,\n",
       "    1.1596465110778809,\n",
       "    1.2127872705459595,\n",
       "    1.1628040075302124,\n",
       "    1.1629813313484192,\n",
       "    1.0489693582057953,\n",
       "    1.04972505569458,\n",
       "    1.111990213394165,\n",
       "    0.9859229922294617,\n",
       "    0.9012497663497925,\n",
       "    1.0234737992286682,\n",
       "    0.8704650104045868,\n",
       "    0.9126956164836884,\n",
       "    0.8087556660175323,\n",
       "    0.8510538637638092,\n",
       "    0.7848677933216095,\n",
       "    0.7965085506439209,\n",
       "    0.768502950668335,\n",
       "    0.7445783913135529,\n",
       "    0.6992000639438629,\n",
       "    0.7651479542255402,\n",
       "    0.7374136447906494,\n",
       "    0.7514752447605133,\n",
       "    0.6860994696617126,\n",
       "    0.5532412827014923,\n",
       "    0.7499729096889496,\n",
       "    0.7328925728797913,\n",
       "    0.5927874445915222,\n",
       "    0.5993754267692566,\n",
       "    0.5634980797767639,\n",
       "    0.6263817548751831,\n",
       "    0.5386340618133545,\n",
       "    0.5529403388500214,\n",
       "    0.5702488422393799,\n",
       "    0.4654344320297241,\n",
       "    0.572065681219101,\n",
       "    0.3947374224662781,\n",
       "    0.7739484310150146,\n",
       "    0.635530486702919,\n",
       "    0.48104605078697205,\n",
       "    0.5088377743959427,\n",
       "    0.4966524988412857,\n",
       "    0.42407359182834625,\n",
       "    0.45034271478652954,\n",
       "    0.39212466776371,\n",
       "    0.35112370550632477,\n",
       "    0.4449876993894577,\n",
       "    0.3491816371679306,\n",
       "    0.33121033012866974,\n",
       "    0.32983389496803284,\n",
       "    0.342890664935112,\n",
       "    0.29973243176937103,\n",
       "    0.26632462441921234,\n",
       "    0.40313920378685,\n",
       "    0.30264994502067566,\n",
       "    0.3135581463575363],\n",
       "   'val_accuracies': [0.0410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4246575342465753,\n",
       "    0.4520547945205479,\n",
       "    0.4383561643835616,\n",
       "    0.410958904109589,\n",
       "    0.410958904109589,\n",
       "    0.4383561643835616,\n",
       "    0.410958904109589,\n",
       "    0.4383561643835616,\n",
       "    0.4520547945205479,\n",
       "    0.3972602739726027,\n",
       "    0.410958904109589,\n",
       "    0.4246575342465753,\n",
       "    0.4383561643835616,\n",
       "    0.4657534246575342,\n",
       "    0.4657534246575342,\n",
       "    0.3972602739726027,\n",
       "    0.4246575342465753,\n",
       "    0.4657534246575342,\n",
       "    0.4794520547945205,\n",
       "    0.4657534246575342,\n",
       "    0.5068493150684932,\n",
       "    0.4383561643835616,\n",
       "    0.4520547945205479,\n",
       "    0.5068493150684932,\n",
       "    0.4383561643835616,\n",
       "    0.4657534246575342,\n",
       "    0.4520547945205479,\n",
       "    0.410958904109589,\n",
       "    0.4657534246575342,\n",
       "    0.4931506849315068,\n",
       "    0.3972602739726027,\n",
       "    0.4383561643835616,\n",
       "    0.3972602739726027,\n",
       "    0.3561643835616438,\n",
       "    0.4246575342465753,\n",
       "    0.4931506849315068,\n",
       "    0.3835616438356164,\n",
       "    0.4657534246575342,\n",
       "    0.4794520547945205,\n",
       "    0.3698630136986301,\n",
       "    0.4520547945205479,\n",
       "    0.5068493150684932,\n",
       "    0.3561643835616438,\n",
       "    0.4383561643835616,\n",
       "    0.4246575342465753,\n",
       "    0.3424657534246575,\n",
       "    0.3287671232876712,\n",
       "    0.4520547945205479,\n",
       "    0.3972602739726027,\n",
       "    0.3972602739726027,\n",
       "    0.4520547945205479,\n",
       "    0.4520547945205479,\n",
       "    0.4794520547945205,\n",
       "    0.4794520547945205,\n",
       "    0.4246575342465753,\n",
       "    0.3835616438356164,\n",
       "    0.4383561643835616,\n",
       "    0.410958904109589,\n",
       "    0.3287671232876712,\n",
       "    0.3835616438356164,\n",
       "    0.4657534246575342,\n",
       "    0.3972602739726027,\n",
       "    0.3561643835616438,\n",
       "    0.4520547945205479],\n",
       "   'cm': array([[ 0,  0,  0,  0,  0,  2,  4,  0],\n",
       "          [ 0,  2,  0,  1,  0,  3,  2,  0],\n",
       "          [ 0,  0,  0,  1,  0,  2,  0,  1],\n",
       "          [ 0,  0,  0,  0,  1,  0,  2,  0],\n",
       "          [ 0,  0,  0,  0,  1,  2,  0,  1],\n",
       "          [ 2,  3,  0,  1,  0, 21,  3,  0],\n",
       "          [ 1,  0,  0,  0,  0,  4,  9,  0],\n",
       "          [ 0,  0,  0,  0,  2,  2,  0,  0]])}}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "480fc524-aa2a-4868-a552-2f4728fc120c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "with open(RESULTS_PATH, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "print(\"\\nAll done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594572f8-4ddd-4239-973e-59045cb2de30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
