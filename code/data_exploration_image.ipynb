{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dataset', 'labels', 'images', 'means', 'stddevs'])\n"
     ]
    }
   ],
   "source": [
    "image_eeg_path = r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\eeg_signals_raw_with_mean_std.pth\"\n",
    "\n",
    "image_eeg = torch.load(image_eeg_path)\n",
    "print(image_eeg.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in image_eeg['dataset']:\n",
    "    assert i['eeg'].float().t()[20:460, :].shape[0] == 440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape a torch tensor of shape (128, 440) to a shape (128, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    'rawData': image_eeg['dataset'],\n",
    "    'mean': image_eeg['means'],\n",
    "    'std': image_eeg['stddevs'],\n",
    "    'labels' : image_eeg['labels'],\n",
    "    'images': image_eeg['images'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "\n",
    "for i in dataset_dict['rawData']:\n",
    "    processed_data.append({\n",
    "        'eeg': i['eeg'].float()[:, 20:460],\n",
    "        'label': i['label'],\n",
    "        'image': i['image']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eeg(eeg_data, original_sfreq, target_sfreq, lowcut=0.5, highcut=75, notch_freq=50, notch_width=3):\n",
    "    \"\"\"\n",
    "    Preprocesses EEG data by applying bandpass and notch filters, and then resamples it.\n",
    "\n",
    "    Args:\n",
    "        eeg_data (numpy.ndarray): EEG data with shape (num_channels, num_samples).\n",
    "        original_sfreq (float): Original sampling frequency of the EEG data.\n",
    "        target_sfreq (float): Target sampling frequency after resampling.\n",
    "        lowcut (float): Lower cutoff frequency for the bandpass filter (Hz).\n",
    "        highcut (float): Upper cutoff frequency for the bandpass filter (Hz).\n",
    "        notch_freq (float): Frequency to notch filter (Hz).\n",
    "        notch_width(float) : Width of the notch filter in Hz.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed and resampled EEG data with shape (num_channels, resampled_samples).\n",
    "    \"\"\"\n",
    "\n",
    "    num_channels, num_samples = eeg_data.shape\n",
    "\n",
    "    # 1. Bandpass Filter\n",
    "    nyquist = 0.5 * original_sfreq\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b_band, a_band = signal.butter(5, [low, high], btype='band')  # 5th order butterworth filter\n",
    "\n",
    "    filtered_data = np.zeros_like(eeg_data, dtype=np.float64)\n",
    "    for channel in range(num_channels):\n",
    "        filtered_data[channel, :] = signal.lfilter(b_band, a_band, eeg_data[channel, :])\n",
    "\n",
    "    # 2. Notch Filter\n",
    "    notch_q = 20\n",
    "    b_notch, a_notch = signal.iirnotch(notch_freq, notch_q, original_sfreq)\n",
    "\n",
    "    notched_data = np.zeros_like(filtered_data, dtype=np.float64)\n",
    "    for channel in range(num_channels):\n",
    "        notched_data[channel, :] = signal.lfilter(b_notch, a_notch, filtered_data[channel, :])\n",
    "\n",
    "    # 3. Resampling\n",
    "    resampled_samples = int(num_samples * target_sfreq / original_sfreq)\n",
    "    resampled_data = np.zeros((num_channels, resampled_samples), dtype=np.float64)\n",
    "\n",
    "    for channel in range(num_channels):\n",
    "        resampled_data[channel, :] = signal.resample(notched_data[channel, :], resampled_samples)\n",
    "\n",
    "    return resampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the EEG data in processed_data\n",
    "for i in range(len(processed_data)):\n",
    "    eeg_data = processed_data[i]['eeg'].numpy()\n",
    "    processed_data[i]['eeg'] = preprocess_eeg(eeg_data, original_sfreq=1000, target_sfreq=200)\n",
    "    # print(\"Shape of EEG data after preprocessing:\", processed_data[i]['eeg'].shape)\n",
    "\n",
    "# dataset_dict['processed'] = processed_data\n",
    "\n",
    "# np.save(r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\processed_eeg_signals.npy\", dataset_dict, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape of eeg data is (128, 88)\n",
    "for i in processed_data:\n",
    "    assert i['eeg'].shape[0] == 128, f\"Shape of EEG data is not correct: {i['eeg'].shape}\"\n",
    "    assert i['eeg'].shape[1] == 88, f\"Shape of EEG data is not correct: {i['eeg'].shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape each np array of shape (128, 88) to a torch tensor of shape (128, 1, 88) for processed_data\n",
    "for i in range(len(processed_data)):\n",
    "    processed_data[i]['eeg'] = torch.from_numpy(processed_data[i]['eeg']).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict['processed'] = processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\processed_eeg_signals.npy\", dataset_dict, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask for the data, put 1 wherever masking is required\n",
    "for i in range(len(processed_data)):\n",
    "    if processed_data[i]['eeg'].shape[2] < 200:\n",
    "        pad_size = 200 - processed_data[i]['eeg'].shape[2]\n",
    "        processed_data[i]['mask'] = torch.ones(1, 200).float()\n",
    "        processed_data[i]['mask'][:, :processed_data[i]['eeg'].shape[2]] = 1e-9\n",
    "        processed_data[i]['eeg'] = torch.nn.functional.pad(processed_data[i]['eeg'], (0, pad_size), 'constant', 0)\n",
    "    # elif processed_data[i]['eeg'].shape[2] > 200:\n",
    "    #     processed_data[i]['mask'] = torch.ones(1, 200).float()\n",
    "    #     processed_data[i]['mask'][:, :processed_data[i]['eeg'].shape[2]] = 0\n",
    "    # else:\n",
    "    #     processed_data[i]['mask'] = torch.ones(1, 200).float()\n",
    "\n",
    "# pad the eeg data to 200 samples\n",
    "# for i in range(len(processed_data)):\n",
    "#     if processed_data[i]['eeg'].shape[2] < 200:\n",
    "#         pad_size = 200 - processed_data[i]['eeg'].shape[2]\n",
    "#         processed_data[i]['eeg'] = torch.nn.functional.pad(processed_data[i]['eeg'], (0, pad_size), 'constant', 0)\n",
    "    # elif processed_data[i]['eeg'].shape[2] > 200:\n",
    "    #     processed_data[i]['eeg'] = processed_data[i]['eeg'][:, :, :200]\n",
    "\n",
    "# save the processed data to a numpy file\n",
    "dataset_dict['processed'] = processed_data\n",
    "np.save(r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\processed_eeg_signals.npy\", dataset_dict, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG data after preprocessing: torch.Size([128, 1, 200])\n",
      "Shape of EEG mask after preprocessing: torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "# load the processed data from the numpy file and print the shape of the data and mask\n",
    "dataset_dict = np.load(r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\processed_eeg_signals.npy\", allow_pickle=True).item()\n",
    "print(\"Shape of EEG data after preprocessing:\", dataset_dict['processed'][0]['eeg'].shape)\n",
    "print(\"Shape of EEG mask after preprocessing:\", dataset_dict['processed'][0]['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rawData', 'mean', 'std', 'labels', 'images', 'processed'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.2282e+00, -2.7308e+00, -1.1331e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 3.9343e+00, -3.6040e+00, -6.5825e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 2.9413e+00,  3.2425e+00,  6.1431e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.4755e+02, -2.4078e+02, -8.7423e+02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.3477e+02, -2.3237e+02, -8.7572e+02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 3.6133e+02, -6.7821e+02, -2.4972e+03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['processed'][0]['eeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_processed = []\n",
    "\n",
    "for i in dataset_dict['rawData']:\n",
    "    half_processed.append({\n",
    "        'eeg': i['eeg'].float()[:, 20:460].unsqueeze(1),\n",
    "        'label': i['label'],\n",
    "        'image': i['image']\n",
    "    })\n",
    "\n",
    "dataset_dict['half_processed'] = half_processed\n",
    "\n",
    "np.save(r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\processed_eeg_signals.npy\", dataset_dict, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of EEG data after preprocessing: torch.Size([128, 1, 200])\n",
      "Shape of EEG mask after preprocessing: torch.Size([1, 200])\n",
      "Shape of non-resampled EEG data: torch.Size([128, 1, 440])\n"
     ]
    }
   ],
   "source": [
    "# load various processed and half processed data and print the shape of the data and mask\n",
    "dataset_dict = np.load(r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\processed_eeg_signals.npy\", allow_pickle=True).item()\n",
    "print(\"Shape of EEG data after preprocessing:\", dataset_dict['processed'][0]['eeg'].shape)\n",
    "print(\"Shape of EEG mask after preprocessing:\", dataset_dict['processed'][0]['mask'].shape)\n",
    "print(\"Shape of non-resampled EEG data:\", dataset_dict['half_processed'][0]['eeg'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the key 'half_processed' from the dataset_dict\n",
    "del dataset_dict['half_processed']\n",
    "\n",
    "# save the dataset_dict again\n",
    "np.save(r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\processed_eeg_signals.npy\", dataset_dict, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rawData', 'mean', 'std', 'labels', 'images', 'processed'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\processed_eeg_signals.npy\", allow_pickle=True).item()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rawData'][0]['subject']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.viz import set_3d_title, set_3d_view\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: pyvistaqt in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: ipyevents in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (2.0.2)\n",
      "Collecting trame\n",
      "  Downloading trame-3.8.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipywidgets) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: pyvista>=0.32.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pyvistaqt) (0.44.1)\n",
      "Requirement already satisfied: QtPy>=1.9.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pyvistaqt) (2.4.3)\n",
      "Collecting trame-server<4,>=3.2.3 (from trame)\n",
      "  Downloading trame_server-3.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting trame-client<4,>=3.4 (from trame)\n",
      "  Downloading trame_client-3.6.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting wslink>=2.1.3 (from trame)\n",
      "  Downloading wslink-2.3.3-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: colorama in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.1 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pyvista>=0.32.0->pyvistaqt) (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pyvista>=0.32.0->pyvistaqt) (2.1.3)\n",
      "Requirement already satisfied: pillow in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pyvista>=0.32.0->pyvistaqt) (11.0.0)\n",
      "Requirement already satisfied: pooch in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pyvista>=0.32.0->pyvistaqt) (1.8.2)\n",
      "Requirement already satisfied: scooby>=0.5.1 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pyvista>=0.32.0->pyvistaqt) (0.10.0)\n",
      "Requirement already satisfied: vtk in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pyvista>=0.32.0->pyvistaqt) (9.4.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pyvista>=0.32.0->pyvistaqt) (4.12.2)\n",
      "Requirement already satisfied: packaging in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from QtPy>=1.9.0->pyvistaqt) (24.2)\n",
      "Collecting more-itertools (from trame-server<4,>=3.2.3->trame)\n",
      "  Downloading more_itertools-10.6.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting aiohttp<4 (from wslink>=2.1.3->trame)\n",
      "  Downloading aiohttp-3.11.14-cp313-cp313-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting msgpack<2,>=1 (from wslink>=2.1.3->trame)\n",
      "  Downloading msgpack-1.1.0-cp313-cp313-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4->wslink>=2.1.3->trame)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4->wslink>=2.1.3->trame)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4->wslink>=2.1.3->trame)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4->wslink>=2.1.3->trame)\n",
      "  Downloading frozenlist-1.5.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4->wslink>=2.1.3->trame)\n",
      "  Downloading multidict-6.2.0-cp313-cp313-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4->wslink>=2.1.3->trame)\n",
      "  Downloading propcache-0.3.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4->wslink>=2.1.3->trame)\n",
      "  Downloading yarl-1.18.3-cp313-cp313-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.32.0->pyvistaqt) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.32.0->pyvistaqt) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.32.0->pyvistaqt) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.32.0->pyvistaqt) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.32.0->pyvistaqt) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from matplotlib>=3.0.1->pyvista>=0.32.0->pyvistaqt) (2.9.0.post0)\n",
      "Requirement already satisfied: wcwidth in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pooch->pyvista>=0.32.0->pyvistaqt) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from pooch->pyvista>=0.32.0->pyvistaqt) (2.32.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.1->pyvista>=0.32.0->pyvistaqt) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from requests>=2.19.0->pooch->pyvista>=0.32.0->pyvistaqt) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from requests>=2.19.0->pooch->pyvista>=0.32.0->pyvistaqt) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from requests>=2.19.0->pooch->pyvista>=0.32.0->pyvistaqt) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\vijay\\nyu\\spring_25\\bdmls\\project\\dataset\\eeg_bdml_env\\lib\\site-packages (from requests>=2.19.0->pooch->pyvista>=0.32.0->pyvistaqt) (2025.1.31)\n",
      "Downloading trame-3.8.1-py3-none-any.whl (31 kB)\n",
      "Downloading trame_client-3.6.1-py3-none-any.whl (237 kB)\n",
      "Downloading trame_server-3.4.0-py3-none-any.whl (37 kB)\n",
      "Downloading wslink-2.3.3-py3-none-any.whl (36 kB)\n",
      "Downloading aiohttp-3.11.14-cp313-cp313-win_amd64.whl (436 kB)\n",
      "Downloading msgpack-1.1.0-cp313-cp313-win_amd64.whl (75 kB)\n",
      "Downloading more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp313-cp313-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.2.0-cp313-cp313-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.3.1-cp313-cp313-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.18.3-cp313-cp313-win_amd64.whl (315 kB)\n",
      "Installing collected packages: trame-client, propcache, multidict, msgpack, more-itertools, frozenlist, attrs, aiohappyeyeballs, yarl, aiosignal, aiohttp, wslink, trame-server, trame\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 attrs-25.3.0 frozenlist-1.5.0 more-itertools-10.6.0 msgpack-1.1.0 multidict-6.2.0 propcache-0.3.1 trame-3.8.1 trame-client-3.6.1 trame-server-3.4.0 wslink-2.3.3 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets pyvistaqt ipyevents trame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_path = r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\actiCAP_snap_CACS_CAS_GACS-v2\\actiCap_snap_CACS_CAS_GACS\\actiCap_slim_for actiChamp_Plus\\CACS-128\\CACS-128_NO_REF.bvef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "montage = mne.channels.read_custom_montage(montage_path)\n",
    "len(montage.ch_names[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synset Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rawData', 'mean', 'std', 'labels', 'images', 'processed'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\processed_eeg_signals.npy\", allow_pickle=True).item()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n03773504',\n",
       " 'n02389026',\n",
       " 'n02504458',\n",
       " 'n03445777',\n",
       " 'n03376595',\n",
       " 'n03584829',\n",
       " 'n03590841',\n",
       " 'n02510455',\n",
       " 'n04044716',\n",
       " 'n03100240',\n",
       " 'n03297495',\n",
       " 'n13054560',\n",
       " 'n02992529',\n",
       " 'n04086273',\n",
       " 'n02690373',\n",
       " 'n02124075',\n",
       " 'n02607072',\n",
       " 'n03180011',\n",
       " 'n03775071',\n",
       " 'n02951358',\n",
       " 'n03272010',\n",
       " 'n03792782',\n",
       " 'n04069434',\n",
       " 'n03197337',\n",
       " 'n02106662',\n",
       " 'n03452741',\n",
       " 'n03792972',\n",
       " 'n07873807',\n",
       " 'n03709823',\n",
       " 'n02281787',\n",
       " 'n02492035',\n",
       " 'n03888257',\n",
       " 'n11939491',\n",
       " 'n02906734',\n",
       " 'n03877472',\n",
       " 'n03272562',\n",
       " 'n07753592',\n",
       " 'n04120489',\n",
       " 'n03982430',\n",
       " 'n03063599']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_synsets = list(set([i.strip().split('_')[0].strip() for i in data['images']]))\n",
    "unique_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (pyproject.toml): started\n",
      "  Building wheel for wget (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9711 sha256=b3a63fbfcd7820fa7edc7c5b150ead122649077fb8de58489b75bcf875ab2873\n",
      "  Stored in directory: c:\\users\\vijayh\\appdata\\local\\pip\\cache\\wheels\\8a\\b8\\04\\0c88fb22489b0c049bee4e977c5689c7fe597d6c4b0e7d0b6a\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "\n",
    "for i in unique_synsets:\n",
    "    links.append(f\"https://image-net.org/data/winter21_whole/{i}.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download n03773504: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03773504.tardln4kod_.tmp'\n",
      "Failed to download n02389026: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02389026.tarz706l1tn.tmp'\n",
      "Failed to download n02504458: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02504458.tarhxew3rku.tmp'\n",
      "Failed to download n03445777: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03445777.tarelp7miio.tmp'\n",
      "Failed to download n03376595: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03376595.tar6d_fbiyf.tmp'\n",
      "Failed to download n03584829: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03584829.tarbtd0hbvd.tmp'\n",
      "Failed to download n03590841: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03590841.tartaqxuuji.tmp'\n",
      "Failed to download n02510455: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02510455.tarij_5eso1.tmp'\n",
      "Failed to download n04044716: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n04044716.tarbjva5o5u.tmp'\n",
      "Failed to download n03100240: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03100240.tar7ex4ocsv.tmp'\n",
      "Failed to download n03297495: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03297495.taruj1k9jwo.tmp'\n",
      "Failed to download n13054560: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n13054560.tar_kmawut_.tmp'\n",
      "Failed to download n02992529: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02992529.tar4bongqua.tmp'\n",
      "Failed to download n04086273: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n04086273.tar9ivdpjq8.tmp'\n",
      "Failed to download n02690373: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02690373.tarahby61zn.tmp'\n",
      "Failed to download n02124075: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02124075.tarbgrq9pd7.tmp'\n",
      "Failed to download n02607072: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02607072.tar06qtdq96.tmp'\n",
      "Failed to download n03180011: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03180011.tarupzs7at9.tmp'\n",
      "Failed to download n03775071: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03775071.taru1409bm4.tmp'\n",
      "Failed to download n02951358: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02951358.tarsa0_k77l.tmp'\n",
      "Failed to download n03272010: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03272010.tar0_nyrnls.tmp'\n",
      "Failed to download n03792782: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03792782.tarsfngoewk.tmp'\n",
      "Failed to download n04069434: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n04069434.tar55efapcw.tmp'\n",
      "Failed to download n03197337: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03197337.tar5max749e.tmp'\n",
      "Failed to download n02106662: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02106662.tar_xbngc0p.tmp'\n",
      "Failed to download n03452741: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03452741.tarcl13m1u6.tmp'\n",
      "Failed to download n03792972: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03792972.tarkthjr2ay.tmp'\n",
      "Failed to download n07873807: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n07873807.tarh3lrd4dd.tmp'\n",
      "Failed to download n03709823: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03709823.tar2vkejxiw.tmp'\n",
      "Failed to download n02281787: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02281787.tarq1w0nnt8.tmp'\n",
      "Failed to download n02492035: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02492035.tar6gxahzwl.tmp'\n",
      "Failed to download n03888257: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03888257.tarbv47acgu.tmp'\n",
      "Failed to download n11939491: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n11939491.tarxfmrye9_.tmp'\n",
      "Failed to download n02906734: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n02906734.taru92mc5cf.tmp'\n",
      "Failed to download n03877472: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03877472.tareskv7mtf.tmp'\n",
      "Failed to download n03272562: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03272562.tarptz0et7m.tmp'\n",
      "Failed to download n07753592: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n07753592.tarpr4tx0w9.tmp'\n",
      "Failed to download n04120489: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n04120489.tar6u56hnwb.tmp'\n",
      "Failed to download n03982430: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03982430.tarw5ptr_f2.tmp'\n",
      "Failed to download n03063599: [Errno 2] No such file or directory: 'D:\\\\Vijay\\\\NYU\\\\Spring_25\\\\BDMLS\\\\Project\\\\dataset\\\\ImageNetEEG\\\\images\\\\n03063599.tartbqmh7wi.tmp'\n"
     ]
    }
   ],
   "source": [
    "out_path = r\"D:\\Vijay\\NYU\\Spring_25\\BDMLS\\Project\\dataset\\ImageNetEEG\\images\"\n",
    "\n",
    "import os\n",
    "import wget\n",
    "\n",
    "for i in unique_synsets:\n",
    "    link = f\"https://image-net.org/data/winter21_whole/{i}.tar\"\n",
    "    try:\n",
    "        filename = wget.download(i, out=os.path.join(out_path, i + \".tar\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_bdml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
